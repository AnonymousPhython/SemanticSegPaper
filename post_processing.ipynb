{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 30 17:09:36 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000                On | 00000000:01:00.0 Off |                  Off |\n",
      "| 41%   41C    P8               14W / 140W|     10MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1566      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      2053      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manidhar/Desktop/AryanWork/yolov8-seg-training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "MODEL = \"Trained_Models/nano_segment_model.pt\"\n",
    "model = YOLO(MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_raised_axle(axle_data,threshhold):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    if(len(axle_data)==0):\n",
    "        return False\n",
    "    if(len(axle_data)==5):\n",
    "        return True\n",
    "\n",
    "    has_raised_axle = False\n",
    "    slopes = []\n",
    "    axle_count = len(axle_data)-1\n",
    "    \n",
    "    np.sort(axle_data)\n",
    "\n",
    "\n",
    "    for i in range(0,axle_count):\n",
    "        slopes.append(int(-1)*(axle_data[axle_count][0]-axle_data[i][0])/(axle_data[axle_count][1]-axle_data[i][1]))\n",
    "\n",
    "    # print(slopes)\n",
    "    std_dev = np.std(slopes)\n",
    "\n",
    "    if(std_dev>=threshhold):\n",
    "        has_raised_axle = True\n",
    "\n",
    "    return has_raised_axle\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axle_inside_bounding_box(bounding_box,axle_data): # both in [x,y,x,y] format\n",
    "\n",
    "    axles_inside_bounding_box = []\n",
    "\n",
    "    bounding_box_x_top = bounding_box[0]\n",
    "    bounding_box_y_top = bounding_box[1]\n",
    "    bounding_box_x_bot = bounding_box[2]\n",
    "    bounding_box_y_bot = bounding_box[3] \n",
    "\n",
    "\n",
    "    for data in axle_data:\n",
    "        x_top = int(data[0])\n",
    "        y_top = int(data[1])\n",
    "\n",
    "        if(bounding_box_x_top<=x_top and x_top<=bounding_box_x_bot and bounding_box_y_top<=y_top and y_top<=bounding_box_y_bot):\n",
    "            axles_inside_bounding_box.append([(data[0]+data[2])/2,(data[1]+data[3])/2])\n",
    "    \n",
    "    return axles_inside_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {0: 'A-10-S-TANDEM', 1: 'A-10-TRIDEM', 2: 'AXLE', 3: 'COMBINED', 4: 'TYPE-2', 5: 'TYPE-2-S2', 6: 'TYPE-3', 7: 'UC'}\n",
    "\n",
    "# modified\n",
    "\n",
    "def contains_raised_axle(filepath_of_image,threshold):\n",
    "\n",
    "    import numpy\n",
    "\n",
    "    result = model(filepath_of_image)\n",
    "    predicted_boxes = []\n",
    "    predicted_classes = []\n",
    "    axles = []\n",
    "    axles_inside_bounding_box = []\n",
    "\n",
    "    if len(result[0]) !=0:\n",
    "        predicted_boxes = result[0].boxes.xyxy.cpu().numpy()\n",
    "        predicted_classes= result[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    for classes in range(len(predicted_classes)):\n",
    "        if(predicted_classes[classes]==2):\n",
    "            axles.append(predicted_boxes[classes])\n",
    "\n",
    "    for classes in range(len(predicted_classes)):\n",
    "        if(predicted_classes[classes] == 3):\n",
    "            axles_inside_bounding_box = get_axle_inside_bounding_box(predicted_boxes[classes],axles)\n",
    "\n",
    "    return predict_raised_axle(axles_inside_bounding_box,threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name_of_image_without_extension(image_path):\n",
    "    import os\n",
    "    image_filename_without_ext = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    return image_filename_without_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lifted_axle_images(path_to_dataset):\n",
    "    \n",
    "    import glob\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    slope_threshold = 0.1\n",
    "    images_with_raised_axle = {\" \"}\n",
    "\n",
    "    for image_path in glob.glob(HOME + path_to_dataset + '/test/images/*.jpg')[:]:\n",
    "        if(contains_raised_axle(image_path,slope_threshold)):\n",
    "            images_with_raised_axle.add(get_file_name_of_image_without_extension(image_path))\n",
    "            # model.predict(image_path,save=True,hide_labels=True)\n",
    "\n",
    "\n",
    "    for images in images_with_raised_axle:\n",
    "        print(images)\n",
    "    \n",
    "    print(len(images_with_raised_axle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.8.10 torch-2.0.0+cu117 CUDA:0 (NVIDIA RTX A4000, 16109MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3259624 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "gjftuyr6f_jpg.rf.69eb480486788251469d8b86efda35b5\n",
      "2023-06-03-09_12_13-620204__00000005_jpg.rf.aec5114f0354b1c4f0dff23dd1bff9a3\n",
      "mainak-1_211_jpg.rf.37fd2f72e4cf2a088807ef796a649d3d\n",
      "mainak-3_593_jpg.rf.1fbf57fe64d52cee47eda86670e16b30\n",
      "2023-06-03-06_31_58-886433__00000015_jpg.rf.056817d58abde5ff7950aa611bfbbcac\n",
      "mainak-3_198_jpg.rf.6d9bec74eb2c786bcb5fd2879ef90e64\n",
      "sravya-14_08_47-766729__00000014_jpg.rf.b0429e0f472d85d152cb0a5888c30934\n",
      "mainak-3_178_jpg.rf.bdbb539e2ceba0078c71deef609e3c63\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = '/MASTERDATASET'\n",
    "\n",
    "get_lifted_axle_images(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A - 13 Test Image 2023-06-03-01_30_16-745497__00000007_jpg.rf.b73b73f7667f37c2d19e53b84ab4e205.jpg\n",
    "\n",
    "contains_raised_axle(\"MASTERDATASET/test/images/2023-06-03-01_30_16-745497__00000007_jpg.rf.b73b73f7667f37c2d19e53b84ab4e205.jpg\",0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type-3-S2 Test Image mainak-3_198_jpg.rf.9ab83c35318e7699f6fc0446239d395b.jpg\n",
    "\n",
    "contains_raised_axle(\"MASTERDATASET/test/images/mainak-3_198_jpg.rf.6d9bec74eb2c786bcb5fd2879ef90e64.jpg\",0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([7, 6])\n",
       " dtype: torch.float32\n",
       "  + tensor([[9.00000e+00, 1.71000e+02, 3.05000e+02, 4.68000e+02, 9.33088e-01, 3.00000e+00],\n",
       "         [1.96000e+02, 3.30000e+02, 2.14000e+02, 3.80000e+02, 8.71050e-01, 2.00000e+00],\n",
       "         [8.90000e+01, 4.10000e+02, 1.17000e+02, 4.67000e+02, 8.68567e-01, 2.00000e+00],\n",
       "         [1.69000e+02, 3.51000e+02, 1.90000e+02, 4.03000e+02, 8.49589e-01, 2.00000e+00],\n",
       "         [2.66000e+02, 2.70000e+02, 2.80000e+02, 3.11000e+02, 8.04015e-01, 2.00000e+00],\n",
       "         [2.80000e+02, 2.59000e+02, 2.94000e+02, 2.97000e+02, 7.61923e-01, 2.00000e+00],\n",
       "         [2.50000e+02, 2.76000e+02, 2.64000e+02, 3.19000e+02, 3.63929e-01, 2.00000e+00]], device='cuda:0')Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Masks'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([7, 640, 640])\n",
       " dtype: torch.float32\n",
       "  + tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"MASTERDATASET/test/images/mainak-1_211_jpg.rf.37fd2f72e4cf2a088807ef796a649d3d.jpg\",save=True,hide_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([7, 6])\n",
       " dtype: torch.float32\n",
       "  + tensor([[ 43.00000, 437.00000, 231.00000, 558.00000,   0.99362,   3.00000],\n",
       "         [ 95.00000, 522.00000, 113.00000, 559.00000,   0.81833,   2.00000],\n",
       "         [161.00000, 494.00000, 175.00000, 526.00000,   0.81003,   2.00000],\n",
       "         [144.00000, 503.00000, 158.00000, 536.00000,   0.79201,   2.00000],\n",
       "         [205.00000, 476.00000, 216.00000, 504.00000,   0.78905,   2.00000],\n",
       "         [217.00000, 471.00000, 227.00000, 498.00000,   0.76277,   2.00000],\n",
       "         [191.00000, 481.00000, 203.00000, 511.00000,   0.69014,   2.00000]], device='cuda:0')Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Masks'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([7, 640, 640])\n",
       " dtype: torch.float32\n",
       "  + tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"MASTERDATASET/test/images/2023-06-03-01_30_16-745497__00000007_jpg.rf.b73b73f7667f37c2d19e53b84ab4e205.jpg\",save=True,hide_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
